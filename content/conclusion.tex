
\section{Conclusion}\label{sec:conclusion}
In this paper, we presented CLMR, a self-supervised contrastive learning framework that learns useful and compact representations of raw waveforms of musical audio. The framework requires no preprocessing of the input and is trained without ground truth, which enables simple and straightforward pre-training on datasets of unprecedented scale. We tested the representations in the music classification task on the MagnaTagATune dataset, achieving competitive performance with state-of-the-art supervised models, exceeding previous supervised benchmarks, and demonstrated the transferability of representations learned from pre-training on different datasets. The simplicity of training the model without a direct supervised signal and without preprocessing inputs, together with encouraging results obtained with a single linear layer optimised for a challenging downstream task, are exciting developments towards unsupervised learning on raw musical signals.

\section{Broader Impact}
