\chapter{Conclusion}\label{sec:conclusion}
In this paper, we presented CLMR, a self-supervised contrastive learning framework that learns useful and compact representations of raw waveforms of musical audio.

The framework requires no preprocessing of the input and is trained without ground truth, which enables simple and straightforward pre-training on datasets of unprecedented scale, requiring no human labeling. We tested the learned, task-agnostic representations by fine-tuning a linear classifier on the music classification task on both the MagnaTagATune and Million Song Dataset, achieving state-of-the-art and competitive performance respectively. We showed that CLMR can achieve comparable downstream task performance using 100$\times$ fewer labels, and demonstrated the out-of-domain transferability of representations learned from pre-training on entirely different datasets of musical audio. We also demonstrated the out-of-domain generalisability of the CLMR model with a listening experiment.

While we hope this research will advance the field of Music Information Retrieval into a new learning paradigm, we would like to put forward the following recommendations:

\begin{itemize}
    \item Care must be taken when compiling a dataset of music for pre-training. The biases that are learned inherently in the CLMR model are not investigated in this research. These biases could lead to a potentially skewed prediction performance in favor of a select genre or type of music.
    \item CLMR requires no human-annotated labels to learn useful representations of music. While normally compensation is provided for human annotation, and, with the absence of this requirement, we recommend instead to compensate artists directly when training this algorithm on their music when developing a commercial application.
\end{itemize}

To foster reproducible research, we published the source code and pre-trained models of this research on GitHub.\footnote{\url{https://github.com/spijkervet/CLMR}}
The simplicity of training the model without a direct supervised signal and without preprocessing inputs, together with encouraging results obtained with a single linear layer optimised for a challenging downstream task, are exciting developments towards unsupervised learning on raw musical audio.