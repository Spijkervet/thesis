\begin{abstract}
% 150 - 200 words
Learning and designing representations lie at the heart of many successful machine learning tasks. Supervised approaches have seen widespread adoption within music information retrieval for learning such representations, but unsupervised representation learning remains challenging. In this paper, we transfer the SimCLR framework to the audio domain and contribute a chain of data augmentations on raw audio and their effectiveness in an ablation study, together to form a simple framework for self-supervised learning of raw audio data: \textit{CLMR}. This approach requires no manual labeling, no fine-tuning and no pre-processing of audio data to learn useful representations. We evaluate the self-supervised learned representations in the downstream task of music classification on the MagnaTagATune and Million Song datasets. A linear classifier fine-tuned on representations from a frozen, pre-trained CLMR model achieves a score of 88.3\% on the MagnaTagATune dataset, challenging fully supervised models that currently achieve a score of 89.0\%. Moreover, we show self-supervised representations from large, unlabeled corpora learned by CLMR transfer well to smaller, labeled musical corpora, indicating that they capture important musical knowledge. To foster reusability and future research on self-supervised learning in MIR, we release pre-trained models and the source code of all experiments of this paper \footnote{\url{https://github.com/spijkervet/CLMR}}.
\end{abstract}


\renewcommand{\abstractname}{Acknowledgements}
\begin{abstract}

\end{abstract}

%% old abstract, which may be too long
% Learning and designing representations lie at the heart of many successful machine learning tasks. Supervised approaches have seen widespread adoption within music information retrieval for learning such representations, but unsupervised representation learning remains challenging. In this paper, we transfer the SimCLR framework to the raw audio domain and contribute a new chain of data augmentations on raw audio, and an ablation study on the effectiveness of the data augmentations, together to form a simple framework for self-supervised learning of raw audio data: \textit{CLMR}. This approach requires no manual labeling, no fine-tuning and no pre-processing of audio data to learn useful representations in the downstream task of music classification. We evaluate the self-supervised learned representations on the MagnaTagATune and Million Song datasets. State-of-the-art, fully supervised models achieve an ROC-AUC score of 89\% on the MagnaTagATune dataset. A linear classifier fine-tuned on music classification using frozen representations from a pre-trained CLMR model achieves a score of 87.7\%. Moreover, when pre-training is performed on other unlabeled, arbitrary corpora, we show that features learned from these corpora are transferable when fine-tuning a linear classifier on the task of music classification on the MagnaTagATune dataset, indicating that the self-supervised model captures and generalises important musical knowledge. To compare the effectiveness of this simple framework with a more complex self-supervised learning objective, we compare Contrastive Predictive Coding with CLMR and show strong autoregressive models are not necessary for learning useful representations in the downstream music classification task. To foster reproducibility and future research on self-supervised learning in MIR, we release pre-trained models and the source code of all experiments of this paper \footnote{\url{https://github.com/spijkervet/CLMR}}.